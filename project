Water Quality Prediction using AI/ML
Here's a comprehensive approach to building a water quality prediction system using machine learning, including Python code examples.

1. Problem Understanding
Water quality prediction involves analyzing various parameters to determine if water is safe for consumption or if it's contaminated. Common parameters include:

pH level

Turbidity

Dissolved Oxygen

Conductivity

Temperature

Biological Oxygen Demand (BOD)

Chemical Oxygen Demand (COD)

Nitrate/Nitrite levels

Heavy metal concentrations

2. Dataset Preparation
You can use publicly available datasets like:

USGS Water Quality Data

Kaggle Water Quality datasets

WHO water quality databases

python
import pandas as pd
import numpy as np

# Load dataset
data = pd.read_csv('water_quality.csv')

# Explore data
print(data.head())
print(data.info())
print(data.describe())
3. Data Preprocessing
python
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.impute import SimpleImputer

# Handle missing values
imputer = SimpleImputer(strategy='mean')
data_imputed = pd.DataFrame(imputer.fit_transform(data), columns=data.columns)

# Separate features and target
X = data_imputed.drop('Potability', axis=1)  # Assuming 'Potability' is the target
y = data_imputed['Potability']

# Feature scaling
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Split data
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)
4. Model Building
Option 1: Random Forest Classifier
python
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

# Initialize model
rf = RandomForestClassifier(n_estimators=100, random_state=42)

# Train model
rf.fit(X_train, y_train)

# Predictions
y_pred = rf.predict(X_test)

# Evaluation
print("Accuracy:", accuracy_score(y_test, y_pred))
print("\nClassification Report:\n", classification_report(y_test, y_pred))
print("\nConfusion Matrix:\n", confusion_matrix(y_test, y_pred))
Option 2: Neural Network
python
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout

# Build model
model = Sequential([
    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),
    Dropout(0.2),
    Dense(32, activation='relu'),
    Dropout(0.2),
    Dense(1, activation='sigmoid')
])

# Compile model
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Train model
history = model.fit(X_train, y_train, epochs=50, batch_size=32, 
                    validation_split=0.2, verbose=1)

# Evaluate model
loss, accuracy = model.evaluate(X_test, y_test)
print(f"Test Accuracy: {accuracy*100:.2f}%")
5. Feature Importance Analysis
python
import matplotlib.pyplot as plt

# For Random Forest
importances = rf.feature_importances_
features = X.columns
indices = np.argsort(importances)[::-1]

plt.figure(figsize=(10,6))
plt.title('Feature Importances')
plt.bar(range(X.shape[1]), importances[indices], align='center')
plt.xticks(range(X.shape[1]), [features[i] for i in indices], rotation=90)
plt.tight_layout()
plt.show()
6. Hyperparameter Tuning
python
from sklearn.model_selection import GridSearchCV

# Define parameter grid
param_grid = {
    'n_estimators': [50, 100, 200],
    'max_depth': [None, 10, 20, 30],
    'min_samples_split': [2, 5, 10]
}

# Grid search
grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, 
                          cv=5, n_jobs=-1, verbose=2)
grid_search.fit(X_train, y_train)

# Best parameters
print("Best Parameters:", grid_search.best_params_)
best_rf = grid_search.best_estimator_
7. Deployment (Flask API Example)
python
from flask import Flask, request, jsonify
import pickle
import numpy as np

# Load saved model
model = pickle.load(open('water_quality_model.pkl', 'rb'))
scaler = pickle.load(open('scaler.pkl', 'rb'))

app = Flask(__name__)

@app.route('/predict', methods=['POST'])
def predict():
    data = request.get_json()
    features = np.array([[
        data['ph'],
        data['Hardness'],
        data['Solids'],
        # ... other features
    ]])
    
    # Scale features
    features_scaled = scaler.transform(features)
    
    # Predict
    prediction = model.predict(features_scaled)
    
    # Return result
    result = "Potable" if prediction[0] == 1 else "Not Potable"
    return jsonify({'prediction': result})

if __name__ == '__main__':
    app.run(debug=True)
8. Advanced Techniques
Time Series Prediction (for continuous monitoring)
python
from statsmodels.tsa.arima.model import ARIMA

# Assuming you have time series data for a specific parameter
ts_data = data['Turbidity'].values

# Fit ARIMA model
model = ARIMA(ts_data, order=(5,1,0))
model_fit = model.fit()

# Forecast next 5 values
forecast = model_fit.forecast(steps=5)
print(forecast)
Anomaly Detection
python
from sklearn.ensemble import IsolationForest

# Train anomaly detection model
clf = IsolationForest(contamination=0.01)
clf.fit(X_scaled)

# Detect anomalies
anomalies = clf.predict(X_scaled)
data['Anomaly'] = anomalies
print(data[data['Anomaly'] == -1])
